{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOY+8inGWyrMkTWpCHF8jKa"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dcAp8nUImRZ3","executionInfo":{"status":"ok","timestamp":1693322555816,"user_tz":-360,"elapsed":33,"user":{"displayName":"Nafisha Juthi","userId":"14550633624761747780"}},"outputId":"20a57c82-c439-4b9d-bbe1-b2b7dbd72c0f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Sample Instance: [1 0 0 0]\n","Predicted Class: 1\n"]}],"source":["import numpy as np\n","\n","# Play Tennis dataset\n","data = [\n","    ['Sunny', 'Hot', 'High', 'Weak', 'No'],\n","    ['Sunny', 'Hot', 'High', 'Strong', 'No'],\n","    ['Overcast', 'Hot', 'High', 'Weak', 'Yes'],\n","    ['Rain', 'Mild', 'High', 'Weak', 'Yes'],\n","    ['Rain', 'Cool', 'Normal', 'Weak', 'Yes'],\n","    ['Rain', 'Cool', 'Normal', 'Strong', 'No'],\n","    ['Overcast', 'Cool', 'Normal', 'Strong', 'Yes'],\n","    ['Sunny', 'Mild', 'High', 'Weak', 'No'],\n","    ['Sunny', 'Cool', 'Normal', 'Weak', 'Yes'],\n","    ['Rain', 'Mild', 'Normal', 'Weak', 'Yes'],\n","    ['Sunny', 'Mild', 'Normal', 'Strong', 'Yes'],\n","    ['Overcast', 'Mild', 'High', 'Strong', 'Yes'],\n","    ['Overcast', 'Hot', 'Normal', 'Weak', 'Yes'],\n","    ['Rain', 'Mild', 'High', 'Strong', 'No']\n","]\n","\n","label_mapping = {'Yes': 1, 'No': 0}\n","for i in data:\n","    i[-1] = label_mapping[i[-1]]\n","\n","# Convert categorical features to numerical values (same as before)\n","feature_mapping = {\n","    'Sunny': 0, 'Overcast': 1, 'Rain': 2,\n","    'Hot': 0, 'Mild': 1, 'Cool': 2,\n","    'High': 0, 'Normal': 1,\n","    'Weak': 0, 'Strong': 1\n","}\n","for instance in data:\n","    for i in range(len(instance) - 1):\n","        instance[i] = feature_mapping[instance[i]]\n","\n","\n","data = np.array(data, dtype=int)\n","\n","\n","class Node:\n","    def __init__(self, feature_index=None, threshold=None, left=None, right=None, value=None):\n","       #The constructor is called when a new instance of the class is created\n","        self.feature_index = feature_index\n","        self.threshold = threshold\n","        self.left = left\n","        self.right = right\n","        self.value = value # the class label assigned to the leaf node\n","\n","\n","def gini_impurity(y):   #array of class labels for a set of data points.\n","#np.unique(y, return_counts=True) returns two values: the unique elements in the array y and their corresponding counts.\n","#By using _ as the variable name, you're indicating that you're not interested in the unique elements themselves, only in the counts.\n","#The counts variable will store the counts of each unique element in the y array.\n","# using _ in this context is a way to signal that you're not using one of the values returned by the function, and you're interested only in the other value\n","    _, counts = np.unique(y, return_counts=True)\n","    #unique values in the class y and their counts\n","    p = counts / len(y)   #probabilities of each class label\n","    gini = 1.0 - np.sum(p ** 2)   #np.sum(probs ** 2) calculates the sum of squared probabilities.\n","    return gini\n","\n","\n","def split_dataset(X, y, feature_index, threshold):\n","    left_mask = X[:, feature_index] == threshold\n","    #creates a boolean mask (left_mask) based on a condition.\n","    #It checks if the values in the column specified by feature_index\n","    #of the array X are equal to the provided threshold\n","    right_mask = ~left_mask\n","    X_left, y_left = X[left_mask], y[left_mask]\n","   # uses the boolean mask left_mask to select the instances\n","   #from arrays X and y that satisfy the condition.\n","   #X_left will contain the feature values of the left subtree instances,\n","  # and y_left will contain their corresponding labels.\n","    X_right, y_right = X[right_mask], y[right_mask]\n","    return X_left, y_left, X_right, y_right\n","\n","\n","\n","\n","def find_best_split(X, y):\n","    num_features = X.shape[1]\n","    best_gini = float('inf')\n","    best_feature = None\n","    best_threshold = None\n","\n","    for feature_index in range(num_features):\n","        unique_values = np.unique(X[:, feature_index])\n","        for threshold in unique_values:\n","            X_left, y_left, X_right, y_right = split_dataset(X, y, feature_index, threshold)\n","            if len(X_left) == 0 or len(X_right) == 0:\n","                continue\n","\n","            gini_left = gini_impurity(y_left)\n","            gini_right = gini_impurity(y_right)\n","            weighted_gini = (len(X_left) / len(X)) * gini_left + (len(X_right) / len(X)) * gini_right\n","\n","            if weighted_gini < best_gini:\n","                best_gini = weighted_gini\n","                best_feature = feature_index\n","                best_threshold = threshold\n","\n","    return best_feature, best_threshold\n","\n","def build_tree(X, y, depth=0, max_depth=3):\n","    if depth >= max_depth or len(np.unique(y)) == 1:\n","        leaf_value = np.argmax(np.bincount(y))\n","        return Node(value=leaf_value)\n","\n","    best_feature, best_threshold = find_best_split(X, y)\n","    if best_feature is None:\n","        leaf_value = np.argmax(np.bincount(y))\n","        return Node(value=leaf_value)\n","\n","    X_left, y_left, X_right, y_right = split_dataset(X, y, best_feature, best_threshold)\n","    left_subtree = build_tree(X_left, y_left, depth + 1, max_depth)\n","    right_subtree = build_tree(X_right, y_right, depth + 1, max_depth)\n","\n","    return Node(feature_index=best_feature, threshold=best_threshold, left=left_subtree, right=right_subtree)\n","\n","\n","\n","def predict_tree(node, x):\n","    if node.value is not None:\n","        return node.value\n","\n","    if x[node.feature_index] == node.threshold:\n","        return predict_tree(node.left, x)\n","    else:\n","        return predict_tree(node.right, x)\n","\n","#def print_tree(node, indent=''):\n","    #if node.value is not None:\n","        #print(f\"{indent}Predict: {node.value}\")\n","   # else:\n","       # print(f\"{indent}Feature {node.feature_index} < {node.threshold}?\")\n","       # print_tree(node.left, indent + '  ')\n","       # print_tree(node.right, indent + '  ')\n","\n","\n","\n","# Separate features (X) and labels (y)\n","X = data[:, :-1]\n","y = data[:, -1]\n","\n","# Build a decision tree\n","tree = build_tree(X, y, max_depth=3)\n","\n","# Sample instance (same as before)\n","sample = np.array([1, 0, 0, 0])  # Overcast, Hot, High, Weak\n","\n","# Predict using the decision tree\n","predicted_class = predict_tree(tree, sample)\n","\n","# Print the decision tree\n","#print_tree(tree)\n","print(f\"Sample Instance: {sample}\")\n","print(f\"Predicted Class: {predicted_class}\")\n"]}]}